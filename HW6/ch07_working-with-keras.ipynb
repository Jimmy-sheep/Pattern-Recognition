{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-2.22567588e-01, -2.76085526e-01,  2.45399714e-01,\n",
       "         -2.07733035e-01, -2.57777750e-01,  1.03906900e-01,\n",
       "          1.35404080e-01, -9.47058648e-02, -1.09674558e-01,\n",
       "          8.65522027e-02, -4.93828356e-02, -2.24060684e-01,\n",
       "         -2.95959115e-02, -1.20684817e-01,  3.52280736e-02,\n",
       "         -7.30842352e-02,  2.26247489e-01,  2.10266173e-01,\n",
       "         -2.73334771e-01, -2.20974267e-01, -1.90448612e-01,\n",
       "         -2.88366050e-01,  2.71689594e-02, -1.32561743e-01,\n",
       "          3.21578681e-02,  1.29430294e-01,  2.46021628e-01,\n",
       "         -6.80308491e-02, -4.03880775e-02,  1.17394060e-01,\n",
       "         -5.62394708e-02,  2.00158060e-02,  1.38124406e-01,\n",
       "          1.03734523e-01,  1.72970712e-01,  2.84157574e-01,\n",
       "          1.28166884e-01, -6.91432953e-02, -2.38432124e-01,\n",
       "          5.08289933e-02, -2.78686047e-01, -1.62914097e-02,\n",
       "          2.18066156e-01, -2.37726629e-01,  2.29367077e-01,\n",
       "          1.22645527e-01, -2.24296272e-01,  2.05545008e-01,\n",
       "          2.55211174e-01,  2.90135324e-01, -8.84738863e-02,\n",
       "          2.62576401e-01, -1.80949777e-01, -2.82784104e-02,\n",
       "          1.97977841e-01, -5.88073283e-02,  1.82730764e-01,\n",
       "         -8.12398195e-02, -1.25744641e-01,  8.06120038e-03,\n",
       "         -2.21182168e-01, -9.40427631e-02,  2.81135201e-01,\n",
       "          1.56286359e-03],\n",
       "        [ 1.22807562e-01, -3.62417102e-02, -9.56994444e-02,\n",
       "          2.55076706e-01, -2.44225532e-01, -1.59809604e-01,\n",
       "         -6.63424730e-02, -2.92752773e-01,  1.64940953e-03,\n",
       "          1.97660267e-01,  2.79799581e-01, -1.21075213e-02,\n",
       "         -5.62835634e-02,  3.97965312e-02,  3.10681760e-02,\n",
       "         -2.08257511e-01, -2.06412613e-01, -1.93523914e-01,\n",
       "         -2.72918403e-01,  2.89076865e-02, -9.36545581e-02,\n",
       "         -2.38438681e-01, -1.66698843e-01,  3.21613550e-02,\n",
       "          8.41697752e-02,  2.27649212e-01, -1.97045326e-01,\n",
       "         -2.66966581e-01,  2.91832745e-01, -2.10689396e-01,\n",
       "         -4.11703885e-02, -2.97195792e-01,  2.12439656e-01,\n",
       "         -1.96403205e-01,  1.62436754e-01, -1.33233905e-01,\n",
       "          4.90111113e-02, -2.81356812e-01, -2.77115405e-01,\n",
       "          2.88258731e-01,  9.91135836e-03, -2.91036367e-01,\n",
       "         -2.35297188e-01,  9.69745815e-02,  1.89339668e-01,\n",
       "          2.34509706e-02,  1.15813315e-02,  3.83783579e-02,\n",
       "         -2.20545962e-01,  2.08258629e-04, -1.98413342e-01,\n",
       "         -8.46693516e-02,  2.52700448e-02, -2.62154281e-01,\n",
       "          7.99606442e-02, -1.16196066e-01, -1.45531282e-01,\n",
       "         -2.52370358e-01, -2.92410225e-01,  2.35031545e-01,\n",
       "          6.41160905e-02,  5.99400401e-02, -1.96518600e-02,\n",
       "          2.59807110e-01],\n",
       "        [ 1.76118493e-01, -2.00090408e-02,  2.08425760e-01,\n",
       "         -5.83950132e-02,  2.86851406e-01,  6.12144470e-02,\n",
       "          1.12098217e-01, -1.98754668e-02, -2.88026303e-01,\n",
       "          2.31226325e-01,  1.68476611e-01,  5.46680987e-02,\n",
       "          2.88509369e-01,  2.36429811e-01,  2.73839355e-01,\n",
       "          1.70177609e-01, -8.79250020e-02,  2.58103371e-01,\n",
       "         -4.21421528e-02,  2.42572427e-01, -2.51759827e-01,\n",
       "         -1.03719905e-01,  8.87233913e-02,  1.17697299e-01,\n",
       "         -1.95148051e-01,  1.56686723e-01, -9.12136883e-02,\n",
       "          1.37711227e-01, -2.07078993e-01,  1.06588483e-01,\n",
       "         -7.23465085e-02,  1.84414208e-01,  3.31287384e-02,\n",
       "         -2.51795858e-01,  1.82804525e-01, -4.36642766e-02,\n",
       "         -2.72398204e-01,  1.90629631e-01, -2.62328088e-01,\n",
       "         -1.86441109e-01,  2.13065028e-01, -1.93065926e-01,\n",
       "          2.72566378e-01, -1.42914325e-01, -1.49518028e-01,\n",
       "          2.10605025e-01,  1.62166864e-01, -1.23416290e-01,\n",
       "          3.73507440e-02, -1.10216156e-01,  1.81891650e-01,\n",
       "         -1.31742358e-02, -2.21271425e-01,  2.97156274e-01,\n",
       "          1.99885964e-01, -1.03418961e-01, -8.76716524e-02,\n",
       "         -1.75857246e-02, -9.26030427e-02,  2.45968223e-01,\n",
       "          8.27793479e-02, -2.28603154e-01, -1.18366599e-01,\n",
       "          1.22146577e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-0.2034797 ,  0.27823707,  0.11094588,  0.02531603, -0.01808858,\n",
       "          0.26059237, -0.06604397,  0.00804466, -0.05289312, -0.14367256],\n",
       "        [-0.03822243, -0.14951813, -0.07162549, -0.23445883,  0.14121395,\n",
       "         -0.01341453, -0.08337219, -0.17144671, -0.15330845, -0.13837782],\n",
       "        [ 0.02218708,  0.2085087 , -0.1223585 ,  0.02759996,  0.23405829,\n",
       "         -0.11748135,  0.1655657 , -0.15169847,  0.14106622,  0.23834947],\n",
       "        [-0.25522116, -0.04278478,  0.22748545, -0.15027645,  0.25318852,\n",
       "         -0.02545989, -0.2843436 , -0.19105735, -0.0289236 ,  0.02582186],\n",
       "        [-0.27605554,  0.05930457,  0.01275474, -0.16179919, -0.0045028 ,\n",
       "          0.26930025,  0.00946605, -0.27070475,  0.14370507, -0.2007325 ],\n",
       "        [ 0.1528804 , -0.2636302 , -0.01430666, -0.1299117 , -0.22822635,\n",
       "         -0.02536994, -0.1452279 ,  0.03428566,  0.11325356, -0.20643267],\n",
       "        [-0.24442902, -0.11967899,  0.2567421 , -0.27771965,  0.00549406,\n",
       "          0.2556189 ,  0.20780158,  0.06379148, -0.09228779, -0.07946748],\n",
       "        [-0.23506719,  0.27908865, -0.07407655, -0.19567436, -0.2691932 ,\n",
       "         -0.10672338,  0.02313808, -0.23567384, -0.02113116, -0.0080224 ],\n",
       "        [-0.01603484,  0.06964576,  0.03106406,  0.13070092, -0.09364164,\n",
       "         -0.049732  , -0.00103265,  0.13972515,  0.20086041, -0.09214556],\n",
       "        [-0.18688849,  0.25416282,  0.05420887,  0.02555805, -0.2432969 ,\n",
       "         -0.14264926,  0.07159948,  0.21279877,  0.17343321,  0.27364746],\n",
       "        [-0.18071805,  0.03897437,  0.02462038, -0.09808762,  0.11389789,\n",
       "         -0.16150999,  0.23502854, -0.14296888, -0.02839351,  0.20721957],\n",
       "        [ 0.14416814,  0.14248326,  0.1973407 ,  0.20845637,  0.15904582,\n",
       "         -0.22383386,  0.0493159 , -0.12869404,  0.20868129, -0.2601328 ],\n",
       "        [ 0.216382  ,  0.04749736, -0.04505302, -0.12958726, -0.19402274,\n",
       "         -0.15333533,  0.15280235,  0.05215761,  0.0594734 , -0.01567954],\n",
       "        [-0.01676074, -0.07246839, -0.13040105,  0.12690464,  0.10563064,\n",
       "         -0.05453353, -0.14227499, -0.07609054, -0.13197832,  0.12507305],\n",
       "        [-0.11001037, -0.12395445, -0.20024893, -0.18025559, -0.03247568,\n",
       "          0.0769541 ,  0.10342202,  0.05217934,  0.03746358,  0.13498002],\n",
       "        [ 0.07579374,  0.0945724 ,  0.11622989,  0.04262   ,  0.04963765,\n",
       "          0.2105633 , -0.2136581 , -0.20349592,  0.24167797,  0.21739945],\n",
       "        [-0.11738876, -0.2304624 , -0.08516616, -0.0340395 , -0.09549338,\n",
       "         -0.03392649, -0.06665009,  0.17885646, -0.08768661,  0.21352321],\n",
       "        [ 0.16956347,  0.13915813,  0.19983411, -0.19377095, -0.04360095,\n",
       "         -0.13421513, -0.16985044, -0.02871484, -0.21028619, -0.17100136],\n",
       "        [-0.23974258,  0.00126845, -0.04978366,  0.13748467, -0.16963224,\n",
       "          0.23378369, -0.12767239, -0.04806194,  0.00336337,  0.18819278],\n",
       "        [-0.12951674, -0.22795269,  0.11677444,  0.07304075, -0.22530916,\n",
       "          0.15728405, -0.1857151 , -0.02085519,  0.18168336, -0.07093288],\n",
       "        [-0.19384155,  0.19875544,  0.0008218 ,  0.2377387 , -0.27485704,\n",
       "          0.26613227,  0.04903513, -0.24715565, -0.09936489, -0.08706658],\n",
       "        [ 0.2312732 , -0.21822438,  0.14739388,  0.09869653, -0.10816751,\n",
       "          0.10401392,  0.23047128, -0.18185914,  0.10853234, -0.0829971 ],\n",
       "        [-0.12022373,  0.22125301,  0.23345104, -0.0471013 ,  0.17531538,\n",
       "          0.28429112, -0.23194823, -0.04313956, -0.04841237,  0.22769132],\n",
       "        [-0.12810098,  0.20914647, -0.0777095 , -0.23395096,  0.03226706,\n",
       "          0.10728538, -0.08735232,  0.02266484,  0.09035906, -0.06758146],\n",
       "        [ 0.2775713 ,  0.23739591,  0.11185268, -0.2548992 , -0.18218555,\n",
       "          0.22946486,  0.24556419,  0.20028442, -0.17253335,  0.18448338],\n",
       "        [-0.18527266, -0.08044325, -0.08339249, -0.06761174,  0.28304508,\n",
       "          0.00831193, -0.11821117,  0.13549632,  0.10479879,  0.01703873],\n",
       "        [-0.05167946,  0.02899235, -0.25866252, -0.16286057,  0.08014786,\n",
       "         -0.2102221 ,  0.25487557, -0.1925078 ,  0.11931694,  0.03411663],\n",
       "        [-0.28058308,  0.26082137,  0.10537517, -0.27446744,  0.07594505,\n",
       "         -0.25623778,  0.06698534,  0.17965898, -0.17849068,  0.20838916],\n",
       "        [ 0.1400288 ,  0.0216184 , -0.17936048, -0.2645831 ,  0.09721899,\n",
       "         -0.17302874,  0.0963451 , -0.28331703,  0.06710562, -0.14420134],\n",
       "        [ 0.18633154,  0.07194707,  0.15609151, -0.25856325,  0.24151465,\n",
       "         -0.05022338,  0.18213475, -0.06613258, -0.11340638, -0.14748466],\n",
       "        [-0.26411754, -0.13540855, -0.24239622,  0.24616262,  0.1478827 ,\n",
       "         -0.02888647,  0.1789822 ,  0.02061546,  0.10411128, -0.0663598 ],\n",
       "        [ 0.11446965, -0.17748666,  0.18632263, -0.1974134 ,  0.02426574,\n",
       "         -0.12295973, -0.10187338, -0.14532918, -0.26566622,  0.1649504 ],\n",
       "        [ 0.20136943,  0.00428563, -0.02520129, -0.09751646, -0.09871566,\n",
       "          0.1253632 ,  0.08052412, -0.24005194, -0.26319587,  0.14468226],\n",
       "        [-0.26457164,  0.23050484,  0.20918515,  0.00935939, -0.1523062 ,\n",
       "         -0.19640511, -0.1195707 ,  0.2166619 , -0.23201829,  0.24345312],\n",
       "        [ 0.21306318,  0.13475212, -0.08350667, -0.08837771,  0.1017985 ,\n",
       "          0.02033576, -0.03217834, -0.2279275 , -0.09904242, -0.27635446],\n",
       "        [-0.05129358, -0.27376187, -0.26630294,  0.21857324,  0.24296466,\n",
       "         -0.08286309,  0.1429027 ,  0.04749051,  0.01515955,  0.11175397],\n",
       "        [ 0.04032969,  0.20202008, -0.15401036, -0.1436932 ,  0.00703013,\n",
       "         -0.19519533, -0.0191538 ,  0.19256455, -0.12420997,  0.09655374],\n",
       "        [ 0.06633759, -0.17871886, -0.19507544,  0.28379014, -0.01011419,\n",
       "         -0.12991415, -0.22735275,  0.23788634,  0.27024886,  0.25612703],\n",
       "        [-0.21386889,  0.16245222,  0.21722963,  0.24706677, -0.07393445,\n",
       "          0.19709235,  0.25875333, -0.12724237,  0.03123447,  0.2588177 ],\n",
       "        [-0.09467673,  0.10386762,  0.2282503 , -0.21426964,  0.23226562,\n",
       "          0.1339828 ,  0.052127  ,  0.10351256,  0.21084261,  0.2796196 ],\n",
       "        [ 0.23545668, -0.279891  ,  0.17343152, -0.04828712, -0.00084841,\n",
       "         -0.05304234,  0.1240539 , -0.02223828, -0.0074999 ,  0.20672268],\n",
       "        [ 0.16176587, -0.20618528, -0.06628262,  0.16243458,  0.20746118,\n",
       "          0.1545189 ,  0.11628142, -0.2319819 , -0.2278998 , -0.05232088],\n",
       "        [ 0.2770376 ,  0.22605065,  0.1035527 , -0.22794855,  0.23593703,\n",
       "         -0.2290417 , -0.25114936, -0.06098047, -0.17780378,  0.1275267 ],\n",
       "        [-0.24983388, -0.20697327,  0.10553363,  0.19607061,  0.21157879,\n",
       "         -0.2666866 , -0.17437437,  0.19221121, -0.10239504, -0.0260601 ],\n",
       "        [-0.07422224, -0.2650796 ,  0.24834976,  0.18796936,  0.27110502,\n",
       "          0.25484845, -0.13525254,  0.12461317,  0.09516343,  0.08093375],\n",
       "        [ 0.24426696,  0.02284616,  0.15603027, -0.25248292, -0.14527792,\n",
       "         -0.06476481,  0.16014373, -0.03547245,  0.07282943, -0.15082873],\n",
       "        [-0.07698058,  0.2809746 , -0.06936993, -0.14125088,  0.0204162 ,\n",
       "         -0.01567498, -0.1642453 ,  0.21425465,  0.26319996, -0.08113702],\n",
       "        [ 0.01922232,  0.2601166 ,  0.00284061, -0.22106051, -0.1907748 ,\n",
       "         -0.05837272, -0.16072935,  0.02121764,  0.11522993, -0.25737315],\n",
       "        [-0.20609865, -0.15758811, -0.2816581 , -0.25244388, -0.00685781,\n",
       "         -0.01595366,  0.00651768,  0.08171237,  0.04205027,  0.16735715],\n",
       "        [-0.02977064, -0.08819149,  0.14045283, -0.18785992,  0.11555529,\n",
       "         -0.2770971 ,  0.28021154, -0.2518239 , -0.253875  , -0.06330153],\n",
       "        [ 0.23690781,  0.1946482 , -0.02034983,  0.09340382, -0.07021122,\n",
       "         -0.08497091,  0.26300105,  0.09856978,  0.02622819,  0.04175124],\n",
       "        [-0.02314752,  0.09140727, -0.23603454,  0.17067671, -0.15607126,\n",
       "         -0.270593  ,  0.13103107, -0.099353  ,  0.26095298, -0.2243913 ],\n",
       "        [ 0.05012855, -0.19635949,  0.03070581,  0.03810918, -0.20894246,\n",
       "          0.25541142, -0.24859823, -0.21827224,  0.21604922,  0.19816276],\n",
       "        [ 0.02454257, -0.2448221 , -0.11461006,  0.1467391 , -0.04426299,\n",
       "          0.25836977, -0.00370479, -0.00352669, -0.03142259,  0.26097968],\n",
       "        [ 0.267664  , -0.10427347, -0.02509573,  0.27642485,  0.08615369,\n",
       "          0.23542598, -0.1724768 , -0.2349509 , -0.06456292,  0.050457  ],\n",
       "        [-0.03504054,  0.04724646, -0.03189006,  0.03592032,  0.18099055,\n",
       "         -0.06993857,  0.05870748, -0.03769296, -0.15543339, -0.16198888],\n",
       "        [-0.01185331,  0.01281095,  0.13570353,  0.1492064 , -0.10242817,\n",
       "         -0.02749914, -0.1328718 , -0.00453627,  0.1388087 ,  0.18919373],\n",
       "        [-0.17063646,  0.0398407 , -0.01069579, -0.2642733 ,  0.21620616,\n",
       "         -0.17871743, -0.08172554,  0.15196988, -0.10454699,  0.23185393],\n",
       "        [-0.00524586, -0.09200299, -0.10811232, -0.15301245, -0.27582923,\n",
       "         -0.05633605, -0.27763358,  0.11962882,  0.16860849, -0.01031065],\n",
       "        [-0.181967  , -0.22709559,  0.24049422,  0.09529671, -0.0956081 ,\n",
       "         -0.18967485,  0.19253829,  0.09248513, -0.09539643,  0.09155336],\n",
       "        [ 0.0300695 ,  0.1943121 ,  0.08730257, -0.19564795,  0.25845054,\n",
       "          0.13324744, -0.126807  ,  0.20156074,  0.22895637, -0.10469893],\n",
       "        [ 0.2753791 , -0.17614959,  0.03607461,  0.2282565 ,  0.00658286,\n",
       "         -0.0916391 , -0.17573059,  0.17394292,  0.05511311,  0.24500111],\n",
       "        [ 0.2303538 ,  0.08769801,  0.21602532, -0.00174996,  0.01226702,\n",
       "          0.12350827,  0.25520757,  0.15339643,  0.12791291,  0.19019076],\n",
       "        [-0.23891047, -0.06151482,  0.17694566, -0.01750287, -0.02374896,\n",
       "         -0.09373036,  0.185696  ,  0.17147985, -0.15609537,  0.24664935]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_first_layer (Dense)       (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "my_last_layer (Dense)        (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_input (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 10ms/step - loss: 28.5954 - priority_loss: 0.3334 - department_loss: 28.2620 - priority_mean_absolute_error: 0.5002 - department_accuracy: 0.2766\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 27.0534 - priority_loss: 0.3425 - department_loss: 26.7109 - priority_mean_absolute_error: 0.5071 - department_accuracy: 0.0633\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 9ms/step - loss: 47.2913 - priority_loss: 0.3425 - department_loss: 46.9488 - priority_mean_absolute_error: 0.5071 - department_accuracy: 0.2688\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 33.7500 - priority_loss: 0.3425 - department_loss: 33.4075 - priority_mean_absolute_error: 0.5071 - department_accuracy: 0.1141\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x2404e2e5580>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x2404e2e5520>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x2404e2e5400>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x2404e2d7c40>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2404e2d7f10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2404e2edb80>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2404e2ed7c0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 9ms/step - loss: 20.3471 - output_1_loss: 0.3278 - output_2_loss: 20.0193 - output_1_mean_absolute_error: 0.4935 - output_2_accuracy: 0.2641\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 8.1561 - output_1_loss: 0.3425 - output_2_loss: 7.8136 - output_1_mean_absolute_error: 0.5071 - output_2_accuracy: 0.3820\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2969 - accuracy: 0.9119 - val_loss: 0.1562 - val_accuracy: 0.9541\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1637 - accuracy: 0.9540 - val_loss: 0.1180 - val_accuracy: 0.9668\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1388 - accuracy: 0.9629 - val_loss: 0.1068 - val_accuracy: 0.9723\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2927 - accuracy: 0.9126 - rmse: 7.1842 - val_loss: 0.1514 - val_accuracy: 0.9555 - val_rmse: 7.3578\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1634 - accuracy: 0.9530 - rmse: 7.3541 - val_loss: 0.1219 - val_accuracy: 0.9672 - val_rmse: 7.4075\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1397 - accuracy: 0.9630 - rmse: 7.3900 - val_loss: 0.1297 - val_accuracy: 0.9686 - val_rmse: 7.4237\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1214 - accuracy: 0.9697 - rmse: 7.4376\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.2936 - accuracy: 0.9132 - val_loss: 0.1500 - val_accuracy: 0.9558\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1651 - accuracy: 0.9539 - val_loss: 0.1252 - val_accuracy: 0.9658\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1401 - accuracy: 0.9631 - val_loss: 0.1193 - val_accuracy: 0.9728\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1269 - accuracy: 0.9686 - val_loss: 0.1037 - val_accuracy: 0.9747\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1166 - accuracy: 0.9704 - val_loss: 0.1055 - val_accuracy: 0.9749\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1128 - accuracy: 0.9727 - val_loss: 0.1040 - val_accuracy: 0.9772\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1029 - accuracy: 0.9753 - val_loss: 0.1085 - val_accuracy: 0.9776\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1051 - accuracy: 0.9759 - val_loss: 0.1128 - val_accuracy: 0.9771\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0984 - accuracy: 0.9780 - val_loss: 0.1137 - val_accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 0.0926 - accuracy: 0.9791 - val_loss: 0.1160 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24132150250>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.2945 - accuracy: 0.9132 - val_loss: 0.1464 - val_accuracy: 0.9576\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1664 - accuracy: 0.9527 - val_loss: 0.1299 - val_accuracy: 0.9656\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1364 - accuracy: 0.9625 - val_loss: 0.1149 - val_accuracy: 0.9739\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1255 - accuracy: 0.9680 - val_loss: 0.1146 - val_accuracy: 0.9716\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1187 - accuracy: 0.9699 - val_loss: 0.1100 - val_accuracy: 0.9741\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1073 - accuracy: 0.9732 - val_loss: 0.1121 - val_accuracy: 0.9764\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1050 - accuracy: 0.9755 - val_loss: 0.1167 - val_accuracy: 0.9750\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1011 - accuracy: 0.9770 - val_loss: 0.1131 - val_accuracy: 0.9777\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0964 - accuracy: 0.9777 - val_loss: 0.1196 - val_accuracy: 0.9784\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0921 - accuracy: 0.9787 - val_loss: 0.1167 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2404aef3250>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2963 - accuracy: 0.9118 - val_loss: 0.1466 - val_accuracy: 0.9587\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1685 - accuracy: 0.9528 - val_loss: 0.1268 - val_accuracy: 0.9674\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1399 - accuracy: 0.9629 - val_loss: 0.1181 - val_accuracy: 0.9675\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1267 - accuracy: 0.9670 - val_loss: 0.1101 - val_accuracy: 0.9747\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1181 - accuracy: 0.9708 - val_loss: 0.1036 - val_accuracy: 0.9764\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1099 - accuracy: 0.9731 - val_loss: 0.1098 - val_accuracy: 0.9755\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1065 - accuracy: 0.9750 - val_loss: 0.1138 - val_accuracy: 0.9767\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0990 - accuracy: 0.9773 - val_loss: 0.1213 - val_accuracy: 0.9772\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0961 - accuracy: 0.9779 - val_loss: 0.1106 - val_accuracy: 0.9790\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0886 - accuracy: 0.9786 - val_loss: 0.1171 - val_accuracy: 0.9777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24132b94f40>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7c3fb68cd310c8e6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7c3fb68cd310c8e6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9138\n",
      "...loss: 0.2914\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9536\n",
      "...loss: 0.1641\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9630\n",
      "...loss: 0.1386\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9678\n",
      "...val_loss: 0.1248\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9678\n",
      "...val_loss: 0.1248\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2944\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1643\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24132ecb1c0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2969 - sparse_categorical_accuracy: 0.9126\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1670 - sparse_categorical_accuracy: 0.9537\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1372 - sparse_categorical_accuracy: 0.9634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24132fd3df0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
